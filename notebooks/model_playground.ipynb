{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evoVAE.utils.datasets import MSA_Dataset\n",
    "import evoVAE.utils.seq_tools as st\n",
    "import evoVAE.utils.metrics as mt\n",
    "from evoVAE.models.seqVAETest import SeqVAETest\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "#pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can be used to test new features for a model without having to use the WandB service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        # Dataset info\n",
    "        \"dataset\": \"playground\",\n",
    "        \"seq_theta\": 0.2, # reweighting \n",
    "        \"AA_count\": 21, # standard AA + gap\n",
    "        \n",
    "        # ADAM \n",
    "        \"learning_rate\": 1e-5, # ADAM\n",
    "        \"weight_decay\": 0.01, # ADAM\n",
    "\n",
    "        # Hidden units \n",
    "        \"momentum\": 0.1, \n",
    "        \"dropout\": 0.5,\n",
    "\n",
    "        # Training loop \n",
    "        \"epochs\": 100,\n",
    "        \"batch_size\": 128,\n",
    "        \"max_norm\": 1.0, # gradient clipping\n",
    "        \n",
    "        # Model info\n",
    "        \"architecture\": \"SeqVAETest\",\n",
    "        \"latent_dims\": 3,\n",
    "        \"hidden_dims\": [32, 16],\n",
    "    }\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "DATA_PATH = \"/Users/sebs_mac/uni_OneDrive/honours/data/gfp_alns/independent_runs/no_synthetic/ancestors/auto_rooted/ancestors/\"\n",
    "filepath = DATA_PATH + 'run_14_ancestors.fa'\n",
    "aln = st.read_aln_file(filepath)\n",
    "aln.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evoVAE.utils.seq_tools as st\n",
    "\n",
    "msa, _, _ = st.convert_msa_numpy_array(aln)\n",
    "msa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit, prange, jit\n",
    "import time\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seqs = aln[\"sequence\"].to_numpy()\n",
    "subset = msa\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evoVAE.utils.seq_tools import encode_and_weight_seqs\n",
    "\n",
    "\n",
    "code, weight = encode_and_weight_seqs(aln['sequence'], 0.2)\n",
    "aln['weight'] = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aln.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train, val = train_test_split(aln, test_size=0.2)\n",
    "\n",
    "\n",
    "# TRAINING\n",
    "train_dataset = MSA_Dataset(\n",
    "    train[\"encoding\"], train['weight'], train[\"id\"]\n",
    ")\n",
    "\n",
    "# VALIDATION\n",
    "val_dataset = MSA_Dataset(\n",
    "    val[\"encoding\"], val['weight'], val[\"id\"]\n",
    ")\n",
    "\n",
    "# DATA LOADERS #\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(len(train_loader), len(val_loader))\n",
    "#next(iter(train_loader))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sequence length \n",
    "SEQ_LEN = 0\n",
    "BATCH_ZERO = 0\n",
    "SEQ_ZERO = 0\n",
    "seq_len = train_dataset[BATCH_ZERO][SEQ_ZERO].shape[SEQ_LEN]\n",
    "input_dims = seq_len * config['AA_count']\n",
    "\n",
    "seq_len, input_dims\n",
    "\n",
    "# use preset structure for hidden dimensions \n",
    "model = SeqVAETest(input_dims=input_dims, latent_dims=config['latent_dims'], hidden_dims=config['hidden_dims'], config=config) \n",
    "\n",
    "model.eval()\n",
    "for encoding, weights, _ in train_loader:\n",
    "\n",
    "    encoding = encoding.float()\n",
    "    weights = weights.float()\n",
    "    #print(encoding.shape, weight.shape)\n",
    "    modelOutputs = model(encoding)\n",
    "    loss, kl, likelihood = model.loss_function(modelOutputs, encoding, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very small nummy data \n",
    "dummy = next(iter(train_loader))[0].float()\n",
    "print(dummy.shape)\n",
    "# reconstruct input, note it has been flattened \n",
    "log_p, z_sample, z_mu, z_logvar = model(dummy)\n",
    "\n",
    "# grab the shape of the input for reshaping\n",
    "orig_shape = log_p.shape[0:-1]\n",
    "\n",
    "# add on extra dim, then make it one-hot encoding shape (obs, seq_len, AA_count)\n",
    "log_p = torch.unsqueeze(log_p, -1)\n",
    "log_p = log_p.view(orig_shape + (-1, config['AA_count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mut_data = pd.read_csv('../data/dms_data/GFP_AEQVI_Sarkisyan_2016.csv')\n",
    "subset = mut_data.copy()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding, _ = st.encode_and_weight_seqs(mut_data['mutated_sequence'], 0.2, reweight=False)\n",
    "mut_data['encoding'] = encoding\n",
    "mut_data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mut_data.to_pickle(\"GFP_AEQVI_Sarkisyan_2016_dms_encoded.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding, weights = st.encode_and_weight_seqs(subset['mutated_sequence'], 0.2, reweight=True)\n",
    "subset['encoding'] = encoding\n",
    "subset['weights'] = weights\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"../data/dms_data/DMS_substitutions.csv\")\n",
    "metadata = metadata[metadata[\"DMS_id\"].str.contains(\"GFP\")]\n",
    "metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "\n",
    "\n",
    "wild_type = metadata['target_seq'].to_numpy()[0]\n",
    "wild_one_hot = torch.Tensor(st.seq_to_one_hot(wild_type)).unsqueeze(0)\n",
    "\n",
    "model.eval()\n",
    "wild_model_encoding, _, _, _ = model(wild_one_hot)\n",
    "\n",
    "orig_shape = wild_model_encoding.shape[0:-1]\n",
    "\n",
    "wild_model_encoding = torch.unsqueeze(wild_model_encoding, -1)\n",
    "\n",
    "wild_model_encoding = wild_model_encoding.view(orig_shape + (-1, model.AA_COUNT))\n",
    "\n",
    "\n",
    "# get the wild type encoding \n",
    "wild_model_encoding = wild_model_encoding.squeeze(0)\n",
    "\n",
    "one_hot = wild_one_hot.squeeze(0)\n",
    "wt_prob = mt.seq_log_probability(one_hot, wild_model_encoding)\n",
    "\n",
    "variant_encodings = torch.Tensor(np.stack(subset['encoding'].values))\n",
    "variant_model_outputs, _, _, _ = model(variant_encodings)\n",
    "\n",
    "model_scores =[]\n",
    "for variant, var_one_hot in zip(variant_model_outputs, variant_encodings):\n",
    "    \n",
    "    print(variant.shape)\n",
    "    var_model_encoding = torch.unsqueeze(variant, -1)\n",
    "    print(var_model_encoding.shape)\n",
    "    var_model_encoding = var_model_encoding.view(orig_shape + (-1, model.AA_COUNT))\n",
    "    var_model_encoding = var_model_encoding.squeeze(0)\n",
    "    log_prob = mt.seq_log_probability(var_one_hot, var_model_encoding)\n",
    "    \n",
    "    # make variant fitness relative to the wild type\n",
    "    model_scores.append(log_prob - wt_prob)\n",
    "    \n",
    "model_scores = pd.Series(model_scores)\n",
    "model_scores, subset['DMS_score']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([0,0,0])\n",
    "b = torch.Tensor([1,2,3])\n",
    "a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spear_rho, k_recall, ndcg, roc_auc = mt.summary_stats(predictions=model_scores, actual=subset['DMS_score'], actual_binned=subset['DMS_score_bin'])\n",
    "spear_rho, k_recall, ndcg, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evoVAE.utils.seq_tools as st\n",
    "from evoVAE.utils.seq_tools import GAPPY_PROTEIN_ALPHABET, calc_position_prob_matrix, calc_mean_seq_embeddings, calc_position_prob_matrix, create_euclidean_dist_matrix, plot_residue_distributions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List\n",
    "\n",
    "seqs = st.read_aln_file(\"../data/test.aln\")\n",
    "encode = calc_mean_seq_embeddings(seqs)\n",
    "ppm = calc_position_prob_matrix(seqs)\n",
    "\n",
    "\n",
    "create_euclidean_dist_matrix(encode, plot=True)\n",
    "\n",
    "\n",
    "plot_residue_distributions(encode)\n",
    "#print(ppm)\n",
    "#print()\n",
    "#print(avgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "all = []\n",
    "\n",
    "with open(\"sample_0.01.output\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        data = line.strip().split(',')\n",
    "        print(data)\n",
    "        all.append(data)\n",
    "\n",
    "        x.append(float(data[0]))\n",
    "        y.append(float(data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(all[-1])\n",
    "error_plus = [(float(all[-1][1]) + float(all[-1][2])/np.sqrt(30000)) for x in range(len(x))]\n",
    "error_neg = [(float(all[-1][1]) - float(all[-1][2])/np.sqrt(30000)) for x in range(len(x))]\n",
    "print(error_plus)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(x,y)\n",
    "plt.plot(x, [float(all[-1][1]) for x in range(len(x))], label='true mean deviation')\n",
    "plt.plot(x,error_plus, '--r', label=\"true mean + 1SD\")\n",
    "plt.plot(x,error_neg, '--r', label=\"true mean - 1SD\")\n",
    "plt.title(\"GFP ancestors\")\n",
    "plt.ylabel(\"Average Euclidean distance from population residue proportions\", size=12)\n",
    "plt.xlabel(\"Proportion of total population sampled\")\n",
    "plt.legend()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac3a727f-afc9-44a0-9afe-5c5ed89ea959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import evoVAE.utils.metrics as mt \n",
    "import evoVAE.utils.seq_tools as st\n",
    "from numba import njit, prange, jit\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1852d8e8",
   "metadata": {},
   "source": [
    "# GB1 clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63433a9b-11ca-4329-84ae-ab55c3f7c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "aln: pd.DataFrame = pd.read_pickle(\"/Users/sebs_mac/uni_OneDrive/honours/data/gb1/encoded_weighted/gb1_ancestors_extants_encoded_weighted_no_dupes.pkl\")\n",
    "aln = aln.drop_duplicates(subset=['sequence'])\n",
    "#aln = aln.sample(frac=0.2)\n",
    "aln.drop(columns=[\"encoding\", \"weights\"], inplace=True)\n",
    "print(aln.shape)\n",
    "aln.head()\n",
    "\n",
    "msa, seq_key, key_label = st.convert_msa_numpy_array(aln)\n",
    "msa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b0012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.write_fasta_file(\"gb1_ancestors_extants_no_dupes.fasta\", aln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1634a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"gb1_an_ex_cluster.tsv\", sep=\"\\t\", header=None)\n",
    "results.columns = [\"cluster\", \"sequence\"]\n",
    "mark_ancestors = lambda x: 1 if \"tree\" in x else 0\n",
    "is_ancestor = results[\"sequence\"].apply(mark_ancestors)\n",
    "results[\"is_ancestor\"] = is_ancestor\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ad2ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "representative_ids = results[\"cluster\"].unique()\n",
    "representative_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985e21c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [results.loc[results[\"cluster\"] == cluster] for cluster in representative_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e36883",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 7000\n",
    "extant_proportions = [0.22, 0.17, 0.12, 0.07, 0.02, 0.0]\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "for p in extant_proportions:\n",
    "    for r in range(1, 6):\n",
    "        sample_ids = st.sample_extant_ancestors(clusters, SAMPLE_SIZE, extant_proportion=p)\n",
    "        sample_seqs = aln.loc[aln[\"id\"].isin(sample_ids)]\n",
    "        st.write_fasta_file(f\"./clusters/gb1_ancestors_extants_no_dupes_clustered_r{r}_extant_{p}.fasta\", sample_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f038a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in extant_proportions:\n",
    "    for r in range(1, 6):\n",
    "        samp_aln = st.read_aln_file(f\"./clusters/gb1_ancestors_extants_no_dupes_clustered_r{r}_extant_{p}.fasta\")\n",
    "        numpy_aln, _, _ = st.convert_msa_numpy_array(samp_aln)\n",
    "        weights = st.reweight_by_seq_similarity(numpy_aln, 0.2)\n",
    "        samp_aln[\"weights\"] = weights\n",
    "        samp_aln.to_pickle(f\"./clusters/gb1_ancestors_extants_no_dupes_clustered_r{r}_extant_{p}_encoded_weighted.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aa0982",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle(\"/Users/sebs_mac/uni_OneDrive/honours/data/gb1/mmseqs_clustering/replicate_encoded_weighted/gb1_ancestors_extants_no_dupes_clustered_r1_extant_0.12_encoded_weighted.pkl\")\n",
    "test.loc[~test[\"id\"].str.contains(\"tree\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff158a6",
   "metadata": {},
   "source": [
    "# A4 human clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e5b3175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>sequence</th>\n",
       "      <th>is_ancestor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N1147_a4_tree_0</td>\n",
       "      <td>N1147_a4_tree_0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N1147_a4_tree_0</td>\n",
       "      <td>N1140_a4_tree_0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N1147_a4_tree_0</td>\n",
       "      <td>N1358_a4_tree_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N1147_a4_tree_0</td>\n",
       "      <td>N1362_a4_tree_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N1147_a4_tree_0</td>\n",
       "      <td>N1387_a4_tree_4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32120</th>\n",
       "      <td>N3313_a4_tree_0</td>\n",
       "      <td>N3907_a4_tree_30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32121</th>\n",
       "      <td>N3313_a4_tree_0</td>\n",
       "      <td>UniRef100_UPI001F080ADC/14-747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32122</th>\n",
       "      <td>N3313_a4_tree_0</td>\n",
       "      <td>UniRef100_A0A8C9ZFS8/9-558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32123</th>\n",
       "      <td>N3313_a4_tree_0</td>\n",
       "      <td>UniRef100_A0A8C9ZCJ7/7-555</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32124</th>\n",
       "      <td>N3313_a4_tree_0</td>\n",
       "      <td>UniRef100_A0A8D0D616/4-548</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32125 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               cluster                        sequence  is_ancestor\n",
       "0      N1147_a4_tree_0                 N1147_a4_tree_0            1\n",
       "1      N1147_a4_tree_0                 N1140_a4_tree_0            1\n",
       "2      N1147_a4_tree_0                 N1358_a4_tree_1            1\n",
       "3      N1147_a4_tree_0                 N1362_a4_tree_1            1\n",
       "4      N1147_a4_tree_0                 N1387_a4_tree_4            1\n",
       "...                ...                             ...          ...\n",
       "32120  N3313_a4_tree_0                N3907_a4_tree_30            1\n",
       "32121  N3313_a4_tree_0  UniRef100_UPI001F080ADC/14-747            0\n",
       "32122  N3313_a4_tree_0      UniRef100_A0A8C9ZFS8/9-558            0\n",
       "32123  N3313_a4_tree_0      UniRef100_A0A8C9ZCJ7/7-555            0\n",
       "32124  N3313_a4_tree_0      UniRef100_A0A8D0D616/4-548            0\n",
       "\n",
       "[32125 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_results = pd.read_csv(\"/Users/sebs_mac/uni_OneDrive/honours/data/a4_human/mmseqs_clustering/a4_an_ex_cluster.tsv\", sep=\"\\t\", header=None)\n",
    "clustering_results.columns = [\"cluster\", \"sequence\"]\n",
    "\n",
    "mark_ancestors = lambda x: 1 if \"tree\" in x else 0\n",
    "is_ancestor = clustering_results[\"sequence\"].apply(mark_ancestors)\n",
    "clustering_results[\"is_ancestor\"] = is_ancestor\n",
    "\n",
    "representative_ids = clustering_results[\"cluster\"].unique()\n",
    "\n",
    "clustering_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deb3b62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the alignment: /Users/sebs_mac/uni_OneDrive/honours/data/a4_human/alns/a4_extants.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Number of seqs: 5230\n"
     ]
    }
   ],
   "source": [
    "aln = st.read_aln_file(\"/Users/sebs_mac/uni_OneDrive/honours/data/a4_human/alns/a4_extants.fasta\", encode=False)\n",
    "encodings, weights = st.encode_and_weight_seqs(aln, 0.2)\n",
    "\n",
    "aln[\"encoding\"] = encodings\n",
    "aln[\"weights\"] = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "328101fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>sequence</th>\n",
       "      <th>is_ancestor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>N1147_a4_tree_0</td>\n",
       "      <td>UniRef100_A0A7N8YDR4/6-565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>N1147_a4_tree_0</td>\n",
       "      <td>UniRef100_A0A7N6BYD0/5-552</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>N1147_a4_tree_0</td>\n",
       "      <td>UniRef100_A0A3Q1JL59/5-546</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>N1147_a4_tree_0</td>\n",
       "      <td>UniRef100_A0A7N9ATZ4/6-548</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>N1681_a4_tree_0</td>\n",
       "      <td>UniRef100_UPI000E1D8C12/26-745</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32081</th>\n",
       "      <td>N3312_a4_tree_0</td>\n",
       "      <td>UniRef100_A0A672J9D9/8-550</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32121</th>\n",
       "      <td>N3313_a4_tree_0</td>\n",
       "      <td>UniRef100_UPI001F080ADC/14-747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32122</th>\n",
       "      <td>N3313_a4_tree_0</td>\n",
       "      <td>UniRef100_A0A8C9ZFS8/9-558</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32123</th>\n",
       "      <td>N3313_a4_tree_0</td>\n",
       "      <td>UniRef100_A0A8C9ZCJ7/7-555</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32124</th>\n",
       "      <td>N3313_a4_tree_0</td>\n",
       "      <td>UniRef100_A0A8D0D616/4-548</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2185 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               cluster                        sequence  is_ancestor\n",
       "29     N1147_a4_tree_0      UniRef100_A0A7N8YDR4/6-565            0\n",
       "30     N1147_a4_tree_0      UniRef100_A0A7N6BYD0/5-552            0\n",
       "31     N1147_a4_tree_0      UniRef100_A0A3Q1JL59/5-546            0\n",
       "32     N1147_a4_tree_0      UniRef100_A0A7N9ATZ4/6-548            0\n",
       "1179   N1681_a4_tree_0  UniRef100_UPI000E1D8C12/26-745            0\n",
       "...                ...                             ...          ...\n",
       "32081  N3312_a4_tree_0      UniRef100_A0A672J9D9/8-550            0\n",
       "32121  N3313_a4_tree_0  UniRef100_UPI001F080ADC/14-747            0\n",
       "32122  N3313_a4_tree_0      UniRef100_A0A8C9ZFS8/9-558            0\n",
       "32123  N3313_a4_tree_0      UniRef100_A0A8C9ZCJ7/7-555            0\n",
       "32124  N3313_a4_tree_0      UniRef100_A0A8D0D616/4-548            0\n",
       "\n",
       "[2185 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_results[clustering_results[\"is_ancestor\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e853687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = [clustering_results.loc[clustering_results[\"cluster\"] == rep] for rep in representative_ids]\n",
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7f99dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the alignment: /Users/sebs_mac/uni_OneDrive/honours/data/a4_human/alns/a4_ancestors_extants_no_dupes.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Number of seqs: 32125\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE = 10000\n",
    "extant_proportions = [0.2185, 0.15, 0.1, 0.05, 0.0]\n",
    "\n",
    "\n",
    "aln = st.read_aln_file(\"/Users/sebs_mac/uni_OneDrive/honours/data/a4_human/alns/a4_ancestors_extants_no_dupes.fasta\", encode=False)\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "for p in extant_proportions:\n",
    "    for r in range(1, 6):\n",
    "        sample_ids = st.sample_extant_ancestors(clusters, SAMPLE_SIZE, extant_proportion=p)\n",
    "        sample_seqs = aln.loc[aln[\"id\"].isin(sample_ids)]\n",
    "        st.write_fasta_file(f\"./a4_ancestors_extants_no_dupes_clustered_r{r}_extant_{p}.fasta\", sample_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5b5e660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r1_extant_0.2185.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r2_extant_0.2185.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r3_extant_0.2185.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r4_extant_0.2185.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r5_extant_0.2185.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r1_extant_0.15.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r2_extant_0.15.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r3_extant_0.15.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r4_extant_0.15.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r5_extant_0.15.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r1_extant_0.1.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r2_extant_0.1.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r3_extant_0.1.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r4_extant_0.1.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r5_extant_0.1.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r1_extant_0.05.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r2_extant_0.05.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r3_extant_0.05.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r4_extant_0.05.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r5_extant_0.05.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r1_extant_0.0.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r2_extant_0.0.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r3_extant_0.0.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r4_extant_0.0.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n",
      "Reading the alignment: ./a4_ancestors_extants_no_dupes_clustered_r5_extant_0.0.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 10000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (10000, 770)\n"
     ]
    }
   ],
   "source": [
    "for p in extant_proportions:\n",
    "    for r in range(1, 6):\n",
    "        samp_aln = st.read_aln_file(f\"./a4_ancestors_extants_no_dupes_clustered_r{r}_extant_{p}.fasta\")\n",
    "        numpy_aln, _, _ = st.convert_msa_numpy_array(samp_aln)\n",
    "        weights = st.reweight_by_seq_similarity(numpy_aln, 0.2)\n",
    "        samp_aln[\"weights\"] = weights\n",
    "        samp_aln.to_pickle(f\"a4_ancestors_extants_no_dupes_clustered_r{r}_extant_{p}_encoded_weighted.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9810d7",
   "metadata": {},
   "source": [
    "# GCN4 clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff08e52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>sequence</th>\n",
       "      <th>is_ancestor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UniRef100_H2B208/41-248</td>\n",
       "      <td>UniRef100_H2B208/41-248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UniRef100_H2B208/41-248</td>\n",
       "      <td>UniRef100_J7RCV7/44-270</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UniRef100_H2B208/41-248</td>\n",
       "      <td>N334_gcn4_tree_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UniRef100_H2B208/41-248</td>\n",
       "      <td>N35_gcn4_tree_7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UniRef100_H2B208/41-248</td>\n",
       "      <td>N32_gcn4_tree_9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11899</th>\n",
       "      <td>N316_gcn4_tree_12</td>\n",
       "      <td>N296_gcn4_tree_12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11900</th>\n",
       "      <td>N315_gcn4_tree_11</td>\n",
       "      <td>N315_gcn4_tree_11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11901</th>\n",
       "      <td>N316_gcn4_tree_10</td>\n",
       "      <td>N316_gcn4_tree_10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11902</th>\n",
       "      <td>N315_gcn4_tree_86</td>\n",
       "      <td>N315_gcn4_tree_86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11903</th>\n",
       "      <td>N315_gcn4_tree_86</td>\n",
       "      <td>N316_gcn4_tree_74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11904 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       cluster                 sequence  is_ancestor\n",
       "0      UniRef100_H2B208/41-248  UniRef100_H2B208/41-248            0\n",
       "1      UniRef100_H2B208/41-248  UniRef100_J7RCV7/44-270            0\n",
       "2      UniRef100_H2B208/41-248         N334_gcn4_tree_1            1\n",
       "3      UniRef100_H2B208/41-248          N35_gcn4_tree_7            1\n",
       "4      UniRef100_H2B208/41-248          N32_gcn4_tree_9            1\n",
       "...                        ...                      ...          ...\n",
       "11899        N316_gcn4_tree_12        N296_gcn4_tree_12            1\n",
       "11900        N315_gcn4_tree_11        N315_gcn4_tree_11            1\n",
       "11901        N316_gcn4_tree_10        N316_gcn4_tree_10            1\n",
       "11902        N315_gcn4_tree_86        N315_gcn4_tree_86            1\n",
       "11903        N315_gcn4_tree_86        N316_gcn4_tree_74            1\n",
       "\n",
       "[11904 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_results = pd.read_csv(\"/Users/sebs_mac/uni_OneDrive/honours/data/gcn4/mmseqs_clustering/gcn4_an_ex_cluster.tsv\", sep=\"\\t\", header=None)\n",
    "clustering_results.columns = [\"cluster\", \"sequence\"]\n",
    "\n",
    "mark_ancestors = lambda x: 1 if \"tree\" in x else 0\n",
    "is_ancestor = clustering_results[\"sequence\"].apply(mark_ancestors)\n",
    "clustering_results[\"is_ancestor\"] = is_ancestor\n",
    "\n",
    "representative_ids = clustering_results[\"cluster\"].unique()\n",
    "\n",
    "clustering_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0521d1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# divide the sequences into their clusters\n",
    "clusters = [clustering_results.loc[clustering_results[\"cluster\"] == rep] for rep in representative_ids]\n",
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "610ba6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the alignment: /Users/sebs_mac/uni_OneDrive/honours/data/gcn4/alns/gcn4_extants.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Number of seqs: 348\n"
     ]
    }
   ],
   "source": [
    "# remove duplcates \n",
    "\n",
    "# aln = st.read_aln_file(\"/Users/sebs_mac/uni_OneDrive/honours/data/gcn4/alns/gcn4_ancestors_extants.fasta\", encode=False)\n",
    "# aln = aln.drop_duplicates(subset=[\"sequence\"])\n",
    "# aln\n",
    "# st.write_fasta_file(\"/Users/sebs_mac/uni_OneDrive/honours/data/gcn4/alns/gcn4_ancestors_extants_no_dupes.fasta\", aln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "44180eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the alignment: /Users/sebs_mac/uni_OneDrive/honours/data/gcn4/alns/gcn4_ancestors_extants_no_dupes.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Number of seqs: 11904\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SAMPLE_SIZE = 5000\n",
    "extant_proportions = [0.0662, 0.05, 0.025, 0.01, 0.0]\n",
    "\n",
    "\n",
    "aln = st.read_aln_file(\"/Users/sebs_mac/uni_OneDrive/honours/data/gcn4/alns/gcn4_ancestors_extants_no_dupes.fasta\", encode=False)\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "for p in extant_proportions:\n",
    "    for r in range(1, 6):\n",
    "        sample_ids = st.sample_extant_ancestors(clusters, SAMPLE_SIZE, extant_proportion=p)\n",
    "        sample_seqs = aln.loc[aln[\"id\"].isin(sample_ids)]\n",
    "        st.write_fasta_file(f\"./gcn4_ancestors_extants_no_dupes_clustered_r{r}_extant_{p}.fasta\", sample_seqs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aa0ec3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r1_extant_0.0662.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r2_extant_0.0662.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r3_extant_0.0662.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r4_extant_0.0662.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r5_extant_0.0662.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r1_extant_0.05.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r2_extant_0.05.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r3_extant_0.05.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r4_extant_0.05.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r5_extant_0.05.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r1_extant_0.025.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r2_extant_0.025.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r3_extant_0.025.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r4_extant_0.025.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r5_extant_0.025.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r1_extant_0.01.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r2_extant_0.01.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r3_extant_0.01.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r4_extant_0.01.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r5_extant_0.01.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r1_extant_0.0.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r2_extant_0.0.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r3_extant_0.0.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r4_extant_0.0.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n",
      "Reading the alignment: ./gcn4_ancestors_extants_no_dupes_clustered_r5_extant_0.0.fasta\n",
      "Checking for bad characters: ['B', 'J', 'X', 'Z', 'U']\n",
      "Performing one hot encoding\n",
      "Number of seqs: 5000\n",
      "Sequence weight numpy array created with shape (num_seqs, columns):  (5000, 281)\n"
     ]
    }
   ],
   "source": [
    "for p in extant_proportions:\n",
    "    for r in range(1, 6):\n",
    "        samp_aln = st.read_aln_file(f\"./gcn4_ancestors_extants_no_dupes_clustered_r{r}_extant_{p}.fasta\")\n",
    "        numpy_aln, _, _ = st.convert_msa_numpy_array(samp_aln)\n",
    "        weights = st.reweight_by_seq_similarity(numpy_aln, 0.2)\n",
    "        samp_aln[\"weights\"] = weights\n",
    "        samp_aln.to_pickle(f\"gcn4_ancestors_extants_no_dupes_clustered_r{r}_extant_{p}_encoded_weighted.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aebe88",
   "metadata": {},
   "source": [
    "# Alternate clustering: incomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d01895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = st.read_aln_file(\"../data/pair_test.aln\")\n",
    "test_msa, _, _ = st.convert_msa_numpy_array(test)\n",
    "\n",
    "@njit(parallel=True)\n",
    "def adj_matrix(msa) -> np.ndarray:\n",
    "\n",
    "    sim_matrix = np.ones((msa.shape[0], msa.shape[0]))\n",
    "    seq_len = len(msa[0])\n",
    "\n",
    "    for i in prange(msa.shape[0]):\n",
    "        for j in prange(i + 1, msa.shape[0]):\n",
    "            dist = 1 - (mt.hamming_distance(msa[i], msa[j]) / seq_len)\n",
    "            sim_matrix[i, j] = sim_matrix[j, i] = dist \n",
    "\n",
    "\n",
    "    return sim_matrix\n",
    "\n",
    "adj_matrix(test_msa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a3fd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = adj_matrix(msa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7604ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering.n_leaves_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a5b7d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.write_fasta_file(data+\"a4_ancestors_extants_no_dupes.fasta\", seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d77e797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N0_a4_tree_2</td>\n",
       "      <td>----LALLLLAAWTARALEVPTDGNAGLLAEPQIAMFCGRLNMHMN...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N1_a4_tree_2</td>\n",
       "      <td>----LALLLLAAWTARALEVPTDGNAGLLAEPQIAMFCGRLNMHMN...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N2_a4_tree_2</td>\n",
       "      <td>----LALLLLAAWTARALEVPTDGNAGLLAEPQIAMFCGRLNMHMN...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N3_a4_tree_2</td>\n",
       "      <td>----LALLLLAAWTARALEVPTDGNAGLLAEPQIAMFCGRLNMHMN...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N4_a4_tree_2</td>\n",
       "      <td>----LALLLLAAWTARALEVPTDGNAGLLAEPQIAMFCGRLNMHMN...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223</th>\n",
       "      <td>N5223_a4_tree_2</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5224</th>\n",
       "      <td>N5224_a4_tree_2</td>\n",
       "      <td>----LALLLLAAWTARALEVPTDGNAGLLAEPQIAMFCGRLNMHMN...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5225</th>\n",
       "      <td>N5225_a4_tree_2</td>\n",
       "      <td>----------------------------------------------...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>N5226_a4_tree_2</td>\n",
       "      <td>----LALLLLAAWTARALEVPTDGNAGLLAEPQIAMFCGRLNMHMN...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5227</th>\n",
       "      <td>N5227_a4_tree_2</td>\n",
       "      <td>------------------YVPTDGNAGLLAEPQIAMFCGRLNMHMN...</td>\n",
       "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5228 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                           sequence  \\\n",
       "0        N0_a4_tree_2  ----LALLLLAAWTARALEVPTDGNAGLLAEPQIAMFCGRLNMHMN...   \n",
       "1        N1_a4_tree_2  ----LALLLLAAWTARALEVPTDGNAGLLAEPQIAMFCGRLNMHMN...   \n",
       "2        N2_a4_tree_2  ----LALLLLAAWTARALEVPTDGNAGLLAEPQIAMFCGRLNMHMN...   \n",
       "3        N3_a4_tree_2  ----LALLLLAAWTARALEVPTDGNAGLLAEPQIAMFCGRLNMHMN...   \n",
       "4        N4_a4_tree_2  ----LALLLLAAWTARALEVPTDGNAGLLAEPQIAMFCGRLNMHMN...   \n",
       "...               ...                                                ...   \n",
       "5223  N5223_a4_tree_2  ----------------------------------------------...   \n",
       "5224  N5224_a4_tree_2  ----LALLLLAAWTARALEVPTDGNAGLLAEPQIAMFCGRLNMHMN...   \n",
       "5225  N5225_a4_tree_2  ----------------------------------------------...   \n",
       "5226  N5226_a4_tree_2  ----LALLLLAAWTARALEVPTDGNAGLLAEPQIAMFCGRLNMHMN...   \n",
       "5227  N5227_a4_tree_2  ------------------YVPTDGNAGLLAEPQIAMFCGRLNMHMN...   \n",
       "\n",
       "                                               encoding  \n",
       "0     [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "1     [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "2     [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "3     [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "4     [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "...                                                 ...  \n",
       "5223  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "5224  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "5225  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "5226  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "5227  [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "\n",
       "[5228 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "22b9efa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4368468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evoVAE.utils.seq_tools as st\n",
    "from evoVAE.utils.datasets import MSA_Dataset\n",
    "from evoVAE.models.seqVAETest import SeqVAETest\n",
    "import evoVAE.utils.statistics as stats\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14276, 4)\n"
     ]
    }
   ],
   "source": [
    "print(test_aln.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>encoding</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N0_gb1_tree_1</td>\n",
       "      <td>MEKEKKVKYFLRKSAFGLASVSAAFLVGSTVFAVDSPIEDTPIIRN...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N1_gb1_tree_1</td>\n",
       "      <td>MEKEKKVKYFLRKSAFGLASVSAAFLVGSTVFAVDSPIEDTPIIRN...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N3_gb1_tree_1</td>\n",
       "      <td>MEKEKKVKYFLRKSAFGLASVSAAFLVGSTVFAVDSPIEDTPIIRN...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>N6_gb1_tree_1</td>\n",
       "      <td>MEKEKKVKYFLRKSAFGLASVSAAFLVGSTVFAVDSPIEDTPIIRN...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>N7_gb1_tree_1</td>\n",
       "      <td>MEKEKKVKYFLRKSAFGLASVSAAFLVGSTTVAADSAIEDTPIIRN...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>0.020408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                           sequence  \\\n",
       "0  N0_gb1_tree_1  MEKEKKVKYFLRKSAFGLASVSAAFLVGSTVFAVDSPIEDTPIIRN...   \n",
       "1  N1_gb1_tree_1  MEKEKKVKYFLRKSAFGLASVSAAFLVGSTVFAVDSPIEDTPIIRN...   \n",
       "3  N3_gb1_tree_1  MEKEKKVKYFLRKSAFGLASVSAAFLVGSTVFAVDSPIEDTPIIRN...   \n",
       "6  N6_gb1_tree_1  MEKEKKVKYFLRKSAFGLASVSAAFLVGSTVFAVDSPIEDTPIIRN...   \n",
       "7  N7_gb1_tree_1  MEKEKKVKYFLRKSAFGLASVSAAFLVGSTTVAADSAIEDTPIIRN...   \n",
       "\n",
       "                                            encoding   weights  \n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  0.021277  \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  0.020833  \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  0.020833  \n",
       "6  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  0.020833  \n",
       "7  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  0.020408  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_aln = st.read_aln_file(\"../data/pair_test.aln\")\n",
    "test_aln = pd.read_pickle(\"../data/gb1/gb1_ancestors_extants_encoded_weighted_no_dupes.pkl\")\n",
    "test_aln.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeqVAETest(\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=9408, out_features=256, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (z_mu_sampler): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (z_logvar_sampler): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (upscale_z): Linear(in_features=2, out_features=64, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Linear(in_features=256, out_features=9408, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_dataset = MSA_Dataset(test_aln[\"encoding\"], test_aln[\"weights\"], test_aln[\"id\"])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=8, shuffle=False\n",
    ")\n",
    "\n",
    "SEQ_LEN = 0\n",
    "BATCH_ZERO = 0\n",
    "SEQ_ZERO = 0\n",
    "seq_len = train_dataset[BATCH_ZERO][SEQ_ZERO].shape[SEQ_LEN]\n",
    "input_dims = seq_len * 21\n",
    "\n",
    "\n",
    "config={\n",
    "            # Dataset info\n",
    "            \"alignment\": \"tets\",\n",
    "            \"seq_theta\": 0.2,  # reweighting\n",
    "            \"AA_count\": 21,  # standard AA + gap\n",
    "            \"test_split\": 0.2,\n",
    "            \"max_mutation\": 4,  # how many mutations the model will test up to\n",
    "            # ADAM\n",
    "            \"learning_rate\": 1e-2,  # ADAM\n",
    "            \"weight_decay\": 1e-4,  # ADAM\n",
    "            # Hidden units\n",
    "            \"momentum\": None,\n",
    "            \"dropout\": None,\n",
    "            # Training loop\n",
    "            \"epochs\": 500,\n",
    "            \"batch_size\": 128,\n",
    "            \"max_norm\": 10,  # gradient clipping\n",
    "            \"patience\": 3,\n",
    "            # Model info - default settings\n",
    "            \"architecture\": f\"SeqVAE_0.25_ancestors_R\",\n",
    "            \"latent_dims\": 2,\n",
    "            \"hidden_dims\": [256, 128, 64],\n",
    "            # DMS data\n",
    "            \"dms_file\": \"../data/SPG1_STRSG_Wu_2016.pkl\",\n",
    "            \"dms_metadata\": \"../data/DMS_substitutions.csv\",\n",
    "            \"dms_id\": \"SPG1_STRSG_Wu_2016\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "SEQ_LEN = 0\n",
    "BATCH_ZERO = 0\n",
    "SEQ_ZERO = 0\n",
    "seq_len = train_dataset[BATCH_ZERO][SEQ_ZERO].shape[SEQ_LEN]\n",
    "input_dims = seq_len * 21\n",
    "\n",
    "\n",
    "good_weights = \"../data/gfp/model_weights/ancestors_extants_no_duplicates_gfp_model_state.pt\"\n",
    "gb1_good = \"../data/gb1/model_weights/gb1_ancestors_extants_no_dupes_model_state.pt\"\n",
    "bad_weights = \"../data/gfp/model_weights/bad_loss/gfp_ancestors_extants_no_duplicates_model_state.pt\"\n",
    "model = SeqVAETest(input_dims, 2, hidden_dims=config[\"hidden_dims\"], config=config)\n",
    "model.load_state_dict(torch.load(gb1_good))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14276\n",
      "14276\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxa</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14271</th>\n",
       "      <td>UniRef100_UPI000768A238/12-386</td>\n",
       "      <td>[0.0941095, 0.60755223]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14272</th>\n",
       "      <td>UniRef100_UPI001959AF38/4-600</td>\n",
       "      <td>[-0.01640377, -1.0976197]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14273</th>\n",
       "      <td>UniRef100_UPI000765255D/5-423</td>\n",
       "      <td>[-0.005554657, 0.9799295]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14274</th>\n",
       "      <td>UniRef100_UPI001454C06F/5-327</td>\n",
       "      <td>[0.04587064, 0.8399803]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14275</th>\n",
       "      <td>UniRef100_A0A1B3PUX7/506-955</td>\n",
       "      <td>[-0.0063712858, -0.40507004]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 taxa                             z\n",
       "14271  UniRef100_UPI000768A238/12-386       [0.0941095, 0.60755223]\n",
       "14272   UniRef100_UPI001959AF38/4-600     [-0.01640377, -1.0976197]\n",
       "14273   UniRef100_UPI000765255D/5-423     [-0.005554657, 0.9799295]\n",
       "14274   UniRef100_UPI001454C06F/5-327       [0.04587064, 0.8399803]\n",
       "14275    UniRef100_A0A1B3PUX7/506-955  [-0.0063712858, -0.40507004]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "names = []\n",
    "z_vals = []\n",
    "\n",
    "num_samples = 50\n",
    "for encoding, weights, name in train_loader:\n",
    "\n",
    "    encoding = encoding.float()\n",
    "    encoding = torch.flatten(encoding, start_dim=1)\n",
    "    #print(encoding.shape)\n",
    "\n",
    "    encoding = encoding.expand(num_samples, encoding.shape[0], encoding.shape[1])\n",
    "    #print(encoding.shape)\n",
    "    #print(encoding.shape)\n",
    "    z_mu, z_logvar = model.encode(encoding.float())\n",
    "    z_samples = model.reparameterise(z_mu, z_logvar)\n",
    "    #print(z_samples.shape)\n",
    "    #print(z_samples[:, 0, :])\n",
    "    mean_z = torch.mean(z_samples, dim=0)\n",
    "    \n",
    "    names.extend(name)\n",
    "    z_vals.extend(mean_z.detach().numpy())\n",
    "\n",
    "\n",
    "print(len(names))\n",
    "print(len(z_vals))\n",
    "id_to_z = pd.DataFrame({\"taxa\": names, \"z\": z_vals})\n",
    "id_to_z.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14276\n",
      "14276\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import evoVAE.utils.seq_tools as st\n",
    "import evoVAE.utils.metrics as mt\n",
    "\n",
    "count = 0\n",
    "inputs = []\n",
    "recons = []\n",
    "# EVALUATE DIFFERENCES BETWEEN THE RECONSTRUCTIONS AND INPUT \n",
    "for id, z in zip(id_to_z['taxa'], id_to_z['z']):\n",
    "\n",
    "    # decode the Z sample and get it into a PPM shape \n",
    "    x_hat = model.decode(torch.tensor(z))\n",
    "    x_hat = x_hat.unsqueeze(-1)\n",
    "    #print(x_hat.shape)\n",
    "\n",
    "    x = test_aln[test_aln['id'] == id]['sequence'].values[0]\n",
    "    x_one_hot = torch.tensor(st.seq_to_one_hot(x))\n",
    "    #print(x_one_hot.shape)\n",
    "\n",
    "    orig_shape = tuple(x_one_hot.shape)\n",
    "    x_hat = x_hat.view(orig_shape)\n",
    "\n",
    "    indices = x_hat.max(dim=-1).indices.tolist()\n",
    "    \n",
    "    orig = test_aln[test_aln['id'] == id]['sequence'].values[0]\n",
    "    inputs.append(orig)\n",
    "    recon = \"\".join([st.GAPPY_PROTEIN_ALPHABET[x] for x in indices])\n",
    "    recons.append(recon)\n",
    "\n",
    "    #hamming_dist += mt.hamming_distance(orig, recon)\n",
    "    #count += 1\n",
    "\n",
    "print(len(recons))\n",
    "print(len(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence weight numpy array created with shape (num_seqs, columns):  (8, 10)\n"
     ]
    }
   ],
   "source": [
    "H = stats.calc_shannon_entropy(test_aln)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence weight numpy array created with shape (num_seqs, columns):  (14276, 448)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m covariances\n\u001b[1;32m     63\u001b[0m msa, _, _ \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mconvert_msa_numpy_array(test_aln)\n\u001b[0;32m---> 64\u001b[0m pairs \u001b[38;5;241m=\u001b[39m \u001b[43mpair_wise_covariances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(pairs\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m#pairs.shape\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 35\u001b[0m, in \u001b[0;36mpair_wise_covariances\u001b[0;34m(msa)\u001b[0m\n\u001b[1;32m     30\u001b[0m col_j \u001b[38;5;241m=\u001b[39m msa[:, j]\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m pairs:\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# find how many sequences have residues a and b\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     col_i_res \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     36\u001b[0m     col_j_res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(col_j \u001b[38;5;241m==\u001b[39m b)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# find how many sequences have this combination \u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from evoVAE.utils.seq_tools import AA_TO_IDX, GAPPY_ALPHABET_LEN\n",
    "import numpy as np\n",
    "\n",
    "def pair_wise_covariances(msa):\n",
    "\n",
    "    SEQ_COUNT = 0\n",
    "    COLS = 1\n",
    "\n",
    "    pairs = []\n",
    "    for i in range(st.GAPPY_ALPHABET_LEN):\n",
    "        pairs.extend([(i, j) for j in range(i + 1, st.GAPPY_ALPHABET_LEN)])\n",
    "\n",
    "    # the number of unique ways we can compare columns in the MSA \n",
    "    column_combinations = (msa.shape[COLS] * (msa.shape[COLS] - 1) // 2)\n",
    "    # number of different residue combinations we can have \n",
    "    aa_combinations = GAPPY_ALPHABET_LEN ** 2\n",
    "\n",
    "    num_seqs = msa.shape[SEQ_COUNT]\n",
    "    num_columns = msa.shape[COLS]\n",
    "\n",
    "    # each column has aa_combinations many ways to combine residues\n",
    "    # this is an upper triangular matrix but we will store it in a linear format. \n",
    "    covariances = np.zeros(column_combinations * aa_combinations)\n",
    "\n",
    "    # keep track of which column combination we're up to \n",
    "    col_combination_count = 0\n",
    "    for i in range(num_columns - 1):\n",
    "        for j in range(i + 1, num_columns):\n",
    "            col_i = msa[:, i]\n",
    "            col_j = msa[:, j]\n",
    "\n",
    "            for a, b in pairs:\n",
    "      \n",
    "                # find how many sequences have residues a and b\n",
    "                col_i_res = np.where(col_i == a)[0]\n",
    "                col_j_res = np.where(col_j == b)[0]\n",
    "\n",
    "                # find how many sequences have this combination \n",
    "                intersect = np.intersect1d(col_i_res, col_j_res, assume_unique=True).shape[SEQ_COUNT]\n",
    "                # make a frequency based on number of sequences \n",
    "                freq_Ai_Bj = intersect / num_seqs\n",
    "                \n",
    "                # just count how many sequences have these residues \n",
    "                freq_Ai = col_i_res.shape[0] / num_seqs\n",
    "                freq_Bj = col_j_res.shape[0] / num_seqs\n",
    "\n",
    "                # get correct position: (which column combination we're at) + (which residue combination we're at)\n",
    "                covar_index = col_combination_count * aa_combinations + a * st.GAPPY_ALPHABET_LEN + b\n",
    "\n",
    "                # useful in case you want to find a specific cov score based on column and residue indices in the upper tri matrix\n",
    "                #col_combination_count = (num_cols*(num_cols-1)/2) - (num_cols-col_1_idx)*((num_cols-col_1_idx)-1)/2 + col_2_idx - col_1_idx - 1\n",
    "                #covar_index = int(col_combination_count * aa_combinations + a_idx * st.GAPPY_ALPHABET_LEN + b_idx)\n",
    "\n",
    "                # (joint occurances of residues a & b at thi) - (occurence of A at col i * occurence of B at col j)\n",
    "                covariances[covar_index] = freq_Ai_Bj - (freq_Ai * freq_Bj)\n",
    "\n",
    "            # keep track of how many column combinations we've seen \n",
    "            col_combination_count += 1\n",
    "\n",
    "    \n",
    "    return covariances\n",
    "\n",
    "msa, _, _ = st.convert_msa_numpy_array(test_aln)\n",
    "pairs = pair_wise_covariances(msa)\n",
    "print(pairs.shape)\n",
    "#pairs.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

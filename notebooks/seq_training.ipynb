{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evoVAE.utils.datasets import MSA_Dataset\n",
    "import evoVAE.utils.seq_tools as st\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from evoVAE.models.seqVAE import SeqVAE\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding the sequences and calculating weights\n",
      "The sequence encoding tensor has size: torch.Size([2, 5, 21])\n",
      "The sequence weight array has size: (2,)\n",
      "\n",
      "Encoding the sequences and calculating weights\n",
      "The sequence encoding tensor has size: torch.Size([1, 5, 21])\n",
      "The sequence weight array has size: (1,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define threshold for sequence similarity \n",
    "THETA = 0.2\n",
    "\n",
    "# Read in the datasets and create train and validation sets \n",
    "alns: pd.DataFrame = st.read_aln_file(\"../data/alignments/tiny.aln\")\n",
    "train, val = train_test_split(alns, test_size=0.2)\n",
    "\n",
    "# create one-hot encodings and calculate reweightings \n",
    "\n",
    "# TRAINING \n",
    "train_encodings, train_weights = st.encode_and_weight_seqs(train[\"sequence\"],theta=THETA)\n",
    "train_ids = train[\"id\"].values # just the seq identifiers \n",
    "train_dataset = MSA_Dataset(train_encodings, train_weights, train_ids)\n",
    "\n",
    "# VALIDATION\n",
    "val_encodings, val_weights = st.encode_and_weight_seqs(val[\"sequence\"], THETA)\n",
    "val_ids = val[\"id\"].values\n",
    "val_dataset = MSA_Dataset(val_encodings, val_weights, val_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 21]), 0.5, 'A0A0J8VL97_PhoQ_UniRef90')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding, weights, id = train_dataset[0]\n",
    "encoding.shape, weights, id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MKLLL'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation = st.one_hot_to_seq(encoding)\n",
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHARS = 21\n",
    "# get the sequence length \n",
    "seq_len = train_dataset[0][0].shape[0]\n",
    "input_dims = seq_len * NUM_CHARS\n",
    "latent_dims = 2\n",
    "\n",
    "\n",
    "# use preset structure for hidden dimensions \n",
    "model = SeqVAE(input_dims=input_dims, latent_dims=latent_dims, hidden_dims=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5, 21]), torch.Size([2]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(val_dataset, batch_size=20)\n",
    "next(iter(train_loader))[0].shape,next(iter(train_loader))[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Value is not broadcastable with batch_shape+event_shape: torch.Size([2, 5, 21]) vs torch.Size([2, 105]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m encoding, weight, name \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      2\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(encoding)\n\u001b[0;32m----> 3\u001b[0m     elbo, kl, likelihood, zlogvar \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(elbo, kl, likelihood)\n",
      "File \u001b[0;32m~/git_repos/evoVAE/evoVAE/models/seqVAE.py:157\u001b[0m, in \u001b[0;36mSeqVAE.loss_function\u001b[0;34m(self, modelOutputs, input)\u001b[0m\n\u001b[1;32m    153\u001b[0m xHat, zSample, zMu, zLogvar \u001b[38;5;241m=\u001b[39m modelOutputs\n\u001b[1;32m    155\u001b[0m kl \u001b[38;5;241m=\u001b[39m KL_divergence(zMu, zLogvar, zSample)\n\u001b[0;32m--> 157\u001b[0m likelihood \u001b[38;5;241m=\u001b[39m \u001b[43mgaussian_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxHat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogStandardDeviation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m elbo \u001b[38;5;241m=\u001b[39m kl \u001b[38;5;241m-\u001b[39m likelihood\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m elbo, kl\u001b[38;5;241m.\u001b[39mdetach(), likelihood\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/git_repos/evoVAE/evoVAE/loss/standard_loss.py:35\u001b[0m, in \u001b[0;36mgaussian_likelihood\u001b[0;34m(xHat, globalLogSD, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m globalStd \u001b[38;5;241m=\u001b[39m globalLogSD\u001b[38;5;241m.\u001b[39mexp()\n\u001b[1;32m     33\u001b[0m qPhi \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mNormal(xHat, globalStd)\n\u001b[0;32m---> 35\u001b[0m log_pxz \u001b[38;5;241m=\u001b[39m \u001b[43mqPhi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# sum up across all dims and then average\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_pxz\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, log_pxz\u001b[38;5;241m.\u001b[39mndim)))\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/embed/lib/python3.8/site-packages/torch/distributions/normal.py:79\u001b[0m, in \u001b[0;36mNormal.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_args:\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# compute the variance\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     var \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/embed/lib/python3.8/site-packages/torch/distributions/distribution.py:297\u001b[0m, in \u001b[0;36mDistribution._validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(actual_shape), \u001b[38;5;28mreversed\u001b[39m(expected_shape)):\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m j \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:\n\u001b[0;32m--> 297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    298\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue is not broadcastable with batch_shape+event_shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactual_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m         )\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     support \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport\n",
      "\u001b[0;31mValueError\u001b[0m: Value is not broadcastable with batch_shape+event_shape: torch.Size([2, 5, 21]) vs torch.Size([2, 105])."
     ]
    }
   ],
   "source": [
    "for encoding, weight, name in train_loader:\n",
    "    outputs = model(encoding)\n",
    "    print(outputs[0].shape)\n",
    "\n",
    "    #elbo, kl, likelihood = model.loss_function(outputs, torch.flatten(encoding, start_dim=-1))\n",
    "    #print(elbo, kl, likelihood)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb1214-bf4e-4e8f-9b92-0c0e00142476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evoVAE.utils.datasets import MSA_Dataset\n",
    "import evoVAE.utils.seq_tools as st\n",
    "import evoVAE.utils.metrics as mt\n",
    "from evoVAE.models.seqVAETest import SeqVAETest\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99645d96-8747-4bef-8275-600ce352d345",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extants_aln = pd.read_pickle(\"../data/gb1/gb1_ancestors_extants_encoded_weighted_no_dupes.pkl\")\n",
    "\n",
    "train_dataset = MSA_Dataset(extants_aln[\"encoding\"], extants_aln[\"weights\"], extants_aln[\"id\"])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=8, shuffle=False\n",
    ")\n",
    "\n",
    "SEQ_LEN = 0\n",
    "BATCH_ZERO = 0\n",
    "SEQ_ZERO = 0\n",
    "seq_len = train_dataset[BATCH_ZERO][SEQ_ZERO].shape[SEQ_LEN]\n",
    "input_dims = seq_len * 21\n",
    "\n",
    "\n",
    "config={\n",
    "            # Dataset info\n",
    "            \"alignment\": \"tets\",\n",
    "            \"seq_theta\": 0.2,  # reweighting\n",
    "            \"AA_count\": 21,  # standard AA + gap\n",
    "            \"test_split\": 0.2,\n",
    "            \"max_mutation\": 4,  # how many mutations the model will test up to\n",
    "            # ADAM\n",
    "            \"learning_rate\": 1e-2,  # ADAM\n",
    "            \"weight_decay\": 1e-4,  # ADAM\n",
    "            # Hidden units\n",
    "            \"momentum\": None,\n",
    "            \"dropout\": None,\n",
    "            # Training loop\n",
    "            \"epochs\": 500,\n",
    "            \"batch_size\": 128,\n",
    "            \"max_norm\": 10,  # gradient clipping\n",
    "            \"patience\": 3,\n",
    "            # Model info - default settings\n",
    "            \"architecture\": f\"SeqVAE_0.25_ancestors_R\",\n",
    "            \"latent_dims\": 3,\n",
    "            \"hidden_dims\": [256, 128, 64],\n",
    "            # DMS data\n",
    "            \"dms_file\": \"../data/SPG1_STRSG_Wu_2016.pkl\",\n",
    "            \"dms_metadata\": \"../data/DMS_substitutions.csv\",\n",
    "            \"dms_id\": \"SPG1_STRSG_Wu_2016\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "SEQ_LEN = 0\n",
    "BATCH_ZERO = 0\n",
    "SEQ_ZERO = 0\n",
    "seq_len = train_dataset[BATCH_ZERO][SEQ_ZERO].shape[SEQ_LEN]\n",
    "input_dims = seq_len * 21\n",
    "\n",
    "\n",
    "good_weights = \"../data/gb1/model_weights/gb1_ancestors_extants_no_dupes_model_state.pt\"\n",
    "bad_weights = \"../data/gfp/model_weights/bad_loss/gfp_ancestors_extants_no_duplicates_model_state.pt\"\n",
    "model = SeqVAETest(input_dims, 2, hidden_dims=config[\"hidden_dims\"], config=config)\n",
    "model.load_state_dict(torch.load(good_weights))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a180e85-360a-4177-9f25-b25a9c127d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = extants_aln.head()\n",
    "ens = np.stack([x.flatten() for x in sub['encoding'].values])\n",
    "sub\n",
    "\n",
    "\n",
    "names = []\n",
    "z_vals = []\n",
    "\n",
    "count = 0 \n",
    "num_samples = 50\n",
    "# SAMPLE Z VALUES FROM THE MODEL FOR EACH EXTANT\n",
    "for encoding, weights, name in train_loader:\n",
    "    #print(encoding.shape)\n",
    "\n",
    "    encoding = torch.flatten(encoding, start_dim=1)\n",
    "    #print(encoding.shape)\n",
    "\n",
    "    encoding = encoding.expand(num_samples, encoding.shape[0], encoding.shape[1])\n",
    "    #print(encoding.shape)\n",
    "    #print(encoding.shape)\n",
    "    z_mu, z_logvar = model.encode(encoding.float())\n",
    "    z_samples = model.reparameterise(z_mu, z_logvar)\n",
    "    #print(z_samples.shape)\n",
    "    #print(z_samples[:, 0, :])\n",
    "    mean_z = torch.mean(z_samples, dim=0)\n",
    "    #print(mean_z.shape)\n",
    "    #print(mean_z[0, :])\n",
    "    #print(list(name))\n",
    "    #print(mean_z)\n",
    "    \n",
    "    names.extend(name)\n",
    "    z_vals.extend(mean_z.detach().numpy())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(len(names))\n",
    "print(len(z_vals))\n",
    "id_to_z = pd.DataFrame({\"taxa\": names, \"z\": z_vals})\n",
    "id_to_z.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf86b3-556e-4fdc-a695-cc1a5c07aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "import evoVAE.utils.seq_tools as st\n",
    "import evoVAE.utils.metrics as mt\n",
    "\n",
    "count = 0\n",
    "inputs = []\n",
    "recons = []\n",
    "hamming_dist = 0\n",
    "# EVALUATE DIFFERENCES BETWEEN THE RECONSTRUCTIONS AND INPUT \n",
    "for id, z in zip(id_to_z['taxa'], id_to_z['z']):\n",
    "\n",
    "    # decode the Z sample and get it into a PPM shape \n",
    "    x_hat = model.decode(torch.tensor(z))\n",
    "    x_hat = x_hat.unsqueeze(-1)\n",
    "    #print(x_hat.shape)\n",
    "\n",
    "    x = extants_aln[extants_aln['id'] == id]['sequence'].values[0]\n",
    "    x_one_hot = torch.tensor(st.seq_to_one_hot(x))\n",
    "    #print(x_one_hot.shape)\n",
    "\n",
    "    orig_shape = tuple(x_one_hot.shape)\n",
    "    x_hat = x_hat.view(orig_shape)\n",
    "\n",
    "    indices = x_hat.max(dim=-1).indices.tolist()\n",
    "    \n",
    "    orig = extants_aln[extants_aln['id'] == id]['sequence'].values[0]\n",
    "    inputs.append(orig)\n",
    "    recon = \"\".join([st.GAPPY_PROTEIN_ALPHABET[x] for x in indices])\n",
    "    recons.append(recon)\n",
    "\n",
    "    #hamming_dist += mt.hamming_distance(orig, recon)\n",
    "    #count += 1\n",
    "    \n",
    "\n",
    "#print(hamming_dist/count)\n",
    "#print(count)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf5f5b-82c4-4175-ba86-a59daef549c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968312aa-60e4-4855-bc1d-e06cc3396622",
   "metadata": {},
   "outputs": [],
   "source": [
    "recons[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e10f8a7-2004-4c33-9814-dc1f53c5f7b3",
   "metadata": {},
   "source": [
    "# Visualisation of the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9005a0b8-59d6-4194-abb2-e6fb3737e6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Filter ancestors and extants\n",
    "ancestors = id_to_z[id_to_z['taxa'].str.contains(\"tree\")]\n",
    "extants = id_to_z[~id_to_z['taxa'].str.contains(\"tree\")]\n",
    "\n",
    "# Combine dataframes\n",
    "to_plot = pd.concat([ancestors, extants])\n",
    "\n",
    "# Scale Z values for RGB encoding\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rgb = scaler.fit_transform(zs)\n",
    "\n",
    "\n",
    "#fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,12),  subplot_kw={'projection': '3d'})\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,12))\n",
    "\n",
    "#ax1 = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax1.set_xlabel('Z1')\n",
    "ax1.set_ylabel('Z2')\n",
    "\n",
    "ax2.set_xlabel('Z1')\n",
    "ax2.set_ylabel('Z2')\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "an_zs = np.array([z.tolist() for z in ancestors['z']])\n",
    "ex_zs = np.array([z.tolist() for z in extants['z']])\n",
    "\n",
    "an_rgb = scaler.fit_transform(np.array([[sum(z)/len(z)] for z in an_zs]))\n",
    "ex_rgb = scaler.fit_transform(np.array([[sum(z)/len(z)] for z in ex_zs]))\n",
    "\n",
    "\n",
    "# Plot ancestors\n",
    "ax1.scatter(an_zs[:, 0], an_zs[:, 1], c=an_rgb, label='Ancestors', s=100, marker='>')\n",
    "ax2.scatter(an_zs[:, 0], an_zs[:, 1], c='red', label='Ancestors', s=100, marker='>')\n",
    "# Plot extants\n",
    "ax1.scatter(ex_zs[:, 0], ex_zs[:, 1], c=ex_rgb, label='Extants', s=100, marker='o')\n",
    "ax2.scatter(ex_zs[:, 0], ex_zs[:, 1], c='blue', label='Extants', s=100, marker='o')\n",
    "\n",
    "ax2.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b5ebbb-9734-49ac-a8f1-a0e4e589e5e6",
   "metadata": {},
   "source": [
    "# Annotation file for tree labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acbacb8-39e1-4fda-94a8-4954f5adf6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rgb_to_hex(rgb):\n",
    "    \"\"\"Return color as #rrggbb for the given color values.\"\"\"\n",
    "    rounded_rgb = tuple(int(round(x)) for x in rgb)\n",
    "    return '#%02X%02X%02X' % rounded_rgb\n",
    "\n",
    "colours = [rgb_to_hex(i) for i in rgb]\n",
    "id_to_z['colours'] = colours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f5f1c-25ee-4ed6-a7ef-91c854927bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_z.to_csv(\"gfp_an_ex_annots.tsv\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46b9c4c-ad57-455f-8c71-80a1d7317d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_z.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cd3818-203b-4623-98df-70265c72374a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
